# LangChain Learning Project

A clean, modular LangChain project designed for learning and experimentation with multiple LLM providers.

## Project Overview

This project provides a flexible framework for working with different Language Model providers (OpenAI, Anthropic, OpenRouter) through a unified interface. It's built with Docker for easy deployment and Jupyter notebooks for interactive learning.

## Quick Start

```bash
# Clone and navigate to project
cd langechain

# Start all services
docker compose up --build

# Access services
- API: http://localhost:8000
- Jupyter: http://localhost:8888
- Vector DB: http://localhost:8001
```

## Project Structure

```
langechain/
â”œâ”€â”€ config/          # Configuration files (YAML)
â”œâ”€â”€ data/            # Data storage and cache
â”œâ”€â”€ examples/        # Example usage scripts
â”œâ”€â”€ notebooks/       # Jupyter notebooks for learning
â”œâ”€â”€ src/             # Main source code
â”œâ”€â”€ tests/           # Unit and integration tests
â””â”€â”€ docker-compose.yaml  # Container orchestration
```

## Key Features

- ğŸ”„ **Multi-Provider Support**: OpenAI, Anthropic, OpenRouter
- ğŸ¯ **Model Auto-Detection**: Automatic provider routing by model name
- ğŸ“ **Model Aliases**: Use simple names like `gpt4`, `claude`, `mistral`
- ğŸ”§ **Configuration-Driven**: YAML-based setup
- ğŸ³ **Docker Ready**: Containerized development environment
- ğŸ“š **Learning Focused**: Jupyter notebooks and examples
- ğŸ”— **Session Management**: Conversation history support
- ğŸŒ **REST API**: FastAPI-based endpoints

## Environment Setup

Copy `.env.example` to `.env` and add your API keys:

```env
OPENAI_API_KEY="your-openai-key"
ANTHROPIC_API_KEY="your-anthropic-key"
OPENROUTER_API_KEY="your-openrouter-key"
```

## Documentation

- See individual folder README files for detailed information
- Check `notebooks/` for interactive tutorials
- Review `examples/` for usage patterns

## Learning Path

1. **Start with**: `notebooks/expiriment.ipynb`
2. **Explore**: `examples/chat_session.py`
3. **Configure**: `config/model_config.yaml`
4. **Build**: Create your own LLM applications

## Contributing

This is a learning project. Feel free to experiment, break things, and learn from the process!

## License

MIT License - See LICENSE file for details
