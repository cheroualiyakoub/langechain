{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c1f4172",
   "metadata": {},
   "source": [
    "1. Extract semantic chunks from your JSON (e.g., abstract, claim, paragraph).\n",
    "\n",
    "2. Use HuggingFaceEmbeddings or OpenAIEmbeddings.\n",
    "\n",
    "3. Store structured info as metadata.\n",
    "\n",
    "4. Use metadata filtering + vector similarity for retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f62f4251-df00-493c-b405-361abc6ada42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Current directory: /app/notebooks\n",
      "üìÅ Project root: /app\n",
      "üìÅ Source directory: /app/src\n",
      "‚úÖ Python paths configured\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Add source directories to Python path\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent  # Go up one level from notebooks to project root\n",
    "src_dir = project_root / \"src\"\n",
    "\n",
    "# Add paths\n",
    "sys.path.append(str(src_dir / \"data_pipline\"))\n",
    "sys.path.append(str(src_dir / \"EU_XML_data_loader\"))\n",
    "\n",
    "\n",
    "from data_pipline import DataPipeline\n",
    "import get_raw_data_paths_EPO  \n",
    "from xml_loader_EPO import process_xml_files_list\n",
    "\n",
    "\n",
    "print(f\"üìÅ Current directory: {current_dir}\")\n",
    "print(f\"üìÅ Project root: {project_root}\")\n",
    "print(f\"üìÅ Source directory: {src_dir}\")\n",
    "print(f\"‚úÖ Python paths configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d61903a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "from langchain.docstore.document import Document\n",
    "import sys\n",
    "# Prepare .json file for embedding\n",
    "def extract_documents(json_data):\n",
    "    bibliographic = json_data.get(\"bibliographic_data\", {})\n",
    "    doc_id = bibliographic.get(\"doc_id\", \"UNKNOWN\")\n",
    "    documents = []\n",
    "\n",
    "    # Common metadata to propagate\n",
    "    common_meta = {\n",
    "        \"doc_id\": doc_id,\n",
    "        \"language\": bibliographic.get(\"language\"),\n",
    "        \"country\": bibliographic.get(\"country\"),\n",
    "        \"doc_number\": bibliographic.get(\"doc_number\"),\n",
    "        \"application_number\": bibliographic.get(\"application_number\"),\n",
    "        \"publication_date\": bibliographic.get(\"publication_date\"),\n",
    "        \"ipc_classes\": bibliographic.get(\"ipc_classes\", []),\n",
    "    }\n",
    "\n",
    "    # Title (en preferred)\n",
    "    title_dict = bibliographic.get(\"title\", {})\n",
    "    title = title_dict.get(\"en\") or next(iter(title_dict.values()), \"\")\n",
    "    if title:\n",
    "        documents.append(Document(\n",
    "            page_content=title,\n",
    "            metadata={**common_meta, \"section\": \"title\"}\n",
    "        ))\n",
    "\n",
    "    # Abstract\n",
    "    abstract = bibliographic.get(\"abstract\")\n",
    "    if abstract:\n",
    "        documents.append(Document(\n",
    "            page_content=abstract,\n",
    "            metadata={**common_meta, \"section\": \"abstract\"}\n",
    "        ))\n",
    "\n",
    "    # Claims\n",
    "    for claim in json_data.get(\"claims\", []):\n",
    "        documents.append(Document(\n",
    "            page_content=claim[\"text\"],\n",
    "            metadata={**common_meta, \"section\": \"claim\", \"claim_number\": claim.get(\"claim_number\")}\n",
    "        ))\n",
    "\n",
    "    # Main sections\n",
    "    for section in json_data.get(\"main_sections\", []):\n",
    "        section_name = section.get(\"heading_text\", \"UNKNOWN_SECTION\")\n",
    "        for p in section.get(\"paragraphs\", []):\n",
    "            documents.append(Document(\n",
    "                page_content=f\"{section_name}\\n{p['text']}\",\n",
    "                metadata={**common_meta, \"section\": section_name, \"p_id\": p.get(\"p_id\")}\n",
    "            ))\n",
    "\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7f0996-5e36-4059-b57e-f6d559a8bc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully imported from data_config.py\n",
      "üîç Testing JSON File Loading Functions\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the new JSON loading functionality\n",
    "sys.path.append(str(src_dir / \"data_pipline\" / \"json_loader\"))\n",
    "\n",
    "# Import the JSON loader functions\n",
    "from json_loader_epo import get_epo_json_file_paths, get_all_json_file_paths, load_json_documents\n",
    "\n",
    "print(\"üîç Testing JSON File Loading Functions\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed2e254-9f1e-442b-8555-f090f5edcc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Found 1286 EPO JSON files\n",
      "Total chunks:  2160\n",
      "Chunks:  page_content='AUDIO SIGNAL ENCODER' metadata={'doc_id': 'EP13899497B9W1', 'language': 'en', 'country': 'EP', 'doc_number': '3084761', 'application_number': '13899497.5', 'publication_date': '20250611', 'ipc_classes': ['G10L  19/038       20130101AFI20170426BHEP', 'G10L  19/07        20130101ALI20170426BHEP'], 'section': 'title', 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ[\"TRANSFORMERS_HTTP_TIMEOUT\"] = \"60\"\n",
    "# load the .json documents\n",
    "file_list = get_epo_json_file_paths()[:50]\n",
    "# file_list = glob.glob(json_files_path)\n",
    "\n",
    "all_documents = []\n",
    "\n",
    "# Preprocessing documents\n",
    "for file_path in file_list:\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        docs = extract_documents(data)\n",
    "        all_documents.extend(docs)\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=50,\n",
    "    add_start_index=True\n",
    "    )\n",
    "all_chunks = splitter.split_documents(all_documents)\n",
    "print(\"Total chunks: \", len(all_chunks))\n",
    "print(\"Chunks: \", all_chunks[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c90d553-59ac-470e-ad5b-d462c74dce6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-18 15:48:03,712 - INFO - Use pytorch device_name: cpu\n",
      "2025-06-18 15:48:03,713 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210c83670a494b08894e97c6ec2be3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a0d2b2304942839e4e832015873969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e468bd4644fe40be84256906b3c3578f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be83e8b25d954cb592c595b4aa8e95a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb60e8dc08f4bdcbfccb633a488c4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e83f3aa9520480e81e4f11231c4705f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14212f58ca1494985f93b9ff892baf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c234a8363d4669b4e36b5bbf24a87d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3c495ead13446eb95f2b02354760f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da0c25938754a118332d2010bc03c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb90473bb5f457aba1ace0b9645c933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vectors = []\n",
    "\n",
    "for chunk in all_chunks:\n",
    "    vector = embeddings.embed_query(chunk.page_content)\n",
    "    vectors.append(vector)\n",
    "\n",
    "# for i, vector in enumerate(vectors[:5]):\n",
    "#     print(f\"Vector {i}: {vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd4f2b97-a068-4979-b64f-369868b9b37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.0281710624694824\n",
      "\n",
      "page_content='Description of Some Embodiments of the Application\n",
      "As used in this application, the term 'circuitry' refers to all of the following:' metadata={'country': 'EP', 'language': 'en', 'doc_id': 'EP13899497B9W1', 'section': 'Description of Some Embodiments of the Application', 'p_id': 'p0171', 'start_index': 0, 'application_number': '13899497.5', 'doc_number': '3084761', 'publication_date': '20250611'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(filter_complex_metadata(all_chunks), embeddings)\n",
    "\n",
    "\n",
    "ids = vector_store.add_documents(documents=all_chunks)\n",
    "\n",
    "# results = vector_store.similarity_search(\"How many paper has written about APPARATUS?\")\n",
    "# print(results[0])\n",
    "\n",
    "results = vector_store.similarity_search_with_score(\n",
    "    \"Which paper mentions about electronics\")\n",
    "doc, score = results[0]\n",
    "print(f\"Score: {score}\\n\")\n",
    "print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8fecc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Document(id='516650fa-da53-46fe-b63d-ec08d845d7c4', metadata={'doc_id': 'EP13899497B9W1', 'application_number': '13899497.5', 'section': 'Description of Some Embodiments of the Application', 'p_id': 'p0015', 'doc_number': '3084761', 'country': 'EP', 'language': 'en', 'publication_date': '20250611', 'start_index': 0}, page_content='Description of Some Embodiments of the Application\\nThe electronic device or apparatus 10 in some embodiments comprises a microphone 11, which is linked via an analogue-to-digital converter (ADC) 14 to a processor 21. The processor 21 is further linked via a digital-to-analogue (DAC) converter 32 to loudspeakers 33. The processor 21 is further linked to a transceiver (RX/TX) 13, to a user interface (UI) 15 and to a memory 22.'), 1.0854408740997314)\n"
     ]
    }
   ],
   "source": [
    "print(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5fb8e6-9daf-429c-b567-65608e800b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
