{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bb133552-b468-428a-982d-e6362564085c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Clé OpenRouter chargée depuis .env\n",
      "✅ Setup Docker terminé\n"
     ]
    }
   ],
   "source": [
    "# Setup pour environnement Docker - Version corrigée\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from typing import Dict, List, Optional, TypedDict, Annotated\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration avec ta clé OpenRouter\n",
    "openai_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "base_url = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "if not openai_api_key:\n",
    "    print(\"❌ Erreur: OPENROUTER_API_KEY non trouvée dans .env\")\n",
    "else:\n",
    "    print(\"✅ Clé OpenRouter chargée depuis .env\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "    os.environ[\"OPENAI_API_BASE\"] = base_url\n",
    "\n",
    "print(\"✅ Setup Docker terminé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5dda0121-3cfd-4905-9001-df8be488d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    from langgraph.graph import StateGraph, END\n",
    "    from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "    from langchain_chroma import Chroma\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    from langchain.schema import Document\n",
    "    import chromadb\n",
    "    import langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cb8c7303-c36b-4ff9-ad99-3d028e886d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "    from langchain.embeddings import HuggingFaceEmbeddings\n",
    "    \n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "        model_kwargs={'device': 'cpu'}\n",
    "    )\n",
    "    \n",
    "    # LLM avec OpenRouter (ça marche)\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"openai/gpt-4.1-nano\",\n",
    "        temperature=0.1,\n",
    "        openai_api_key=openai_api_key,\n",
    "        openai_api_base=base_url\n",
    "    )\n",
    "    \n",
    "    # Chroma avec embeddings locaux\n",
    "    vector_store = Chroma(\n",
    "        collection_name=\"patent_collection\",\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=\"./chroma_db\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "282d3b57-f023-4ee0-adc6-e70b3ab4d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Charger tous les templates dynamiquement\n",
    "import os\n",
    "import json\n",
    "from langchain.schema import Document\n",
    "\n",
    "TEMPLATE_DIR = \"./\"\n",
    "template_files = [f for f in os.listdir(TEMPLATE_DIR) if f.startswith(\"template_\") and f.endswith(\".json\")]\n",
    "\n",
    "docs = []\n",
    "for fname in template_files:\n",
    "    with open(os.path.join(TEMPLATE_DIR, fname), \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=json.dumps(data, indent=2),\n",
    "                metadata={\"source\": fname}\n",
    "            )\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "82c42745-3bb4-48cd-822d-ecf97840a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Splitter et vectoriser tous les templates\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_docs = splitter.split_documents(docs)\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"patent_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "vector_store.add_documents(split_docs)\n",
    "\n",
    "# 3. Créer un Retriever avec mémoire de conversation (nouvelle méthode)\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f4df05a6-dc66-4ac1-b970-1fe0694ed585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_blue_bold_animated(text):\n",
    "    \"\"\"Affiche le texte en bleu gras avec animation lettre par lettre\"\"\"\n",
    "    if not text or str(text).strip() == \"\":\n",
    "        print(\"⚠️ Réponse vide reçue.\")\n",
    "        return\n",
    "    \n",
    "    html_start = '<span style=\"color:#1976d2; font-weight:bold; font-size:1.1em\">'\n",
    "    html_end = '</span>'\n",
    "    s = \"\"\n",
    "    display_id = str(uuid.uuid4())\n",
    "    \n",
    "    for c in str(text):\n",
    "        s += c\n",
    "        display(HTML(html_start + s + html_end), display_id=display_id, update=True)\n",
    "        time.sleep(0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e80b9-8d27-4991-b382-3f124eebc1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Pose ta question sur les templates (ou 'quit'):  \"Tell me about drought-resistant crops\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: KeyError('output')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse: Based on the provided context, the invention pertains to genetically modified plants with enhanced drought resistance. These modifications involve introducing specific drought-tolerance genes, utilizing technologies such as CRISPR-Cas9, and employing plant transformation protocols. The resulting transgenic plants demonstrate improved water use efficiency, reduced water loss, and sustained crop yields under water-stressed conditions, particularly in arid and semi-arid environments.\n",
      "\n",
      "If you have specific questions about patentability, patent claims, prior art, or patent application procedures related to drought-resistant crops, I can provide detailed expertise in those areas.\n",
      "Sources: ['template_biotech_agriculture.json', 'template_biotech_agriculture.json', 'template_biotech_agriculture.json']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Classe pour stocker l'historique des messages\n",
    "class InMemoryHistory(BaseChatMessageHistory):\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "    \n",
    "    def add_messages(self, messages):\n",
    "        self.messages.extend(messages)\n",
    "    \n",
    "    def clear(self):\n",
    "        self.messages = []\n",
    "\n",
    "# Créer l'historique\n",
    "chat_history = InMemoryHistory()\n",
    "\n",
    "# Template de prompt avec historique\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Act as a patent expert. Analyze the provided context and answer each question with precision and expertise, but only if it concerns patents. If a question falls outside the field of patents, clearly state that your expertise is limited to patent-related topics and you are unable to provide assistance otherwise.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"system\", \"Contexte: {context}\")\n",
    "])\n",
    "\n",
    "# Créer les chaînes\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "# Ajouter l'historique\n",
    "conversational_chain = RunnableWithMessageHistory(\n",
    "    retrieval_chain,\n",
    "    lambda session_id: chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "# 4. Boucle de chat avec mémoire de conversation\n",
    "session_id = \"session_1\"\n",
    "while True:\n",
    "    question = input(\"Pose ta question sur les templates (ou 'quit'): \")\n",
    "    if question.lower() in [\"quit\", \"exit\"]:\n",
    "        break\n",
    "    \n",
    "    result = conversational_chain.invoke(\n",
    "        {\"input\": question},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "    print(\"Réponse:\", result[\"answer\"])\n",
    "    print(\"Sources:\", [doc.metadata.get(\"source\", \"Unknown\") for doc in result.get(\"context\", [])])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fdb025-aba8-45c0-875b-3a72aaf41833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
