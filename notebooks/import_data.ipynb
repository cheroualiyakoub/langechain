{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cc2db46-8f22-4154-85e8-2b41f26dde8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Setting up paths...\n",
      "Current working directory: /app/notebooks\n",
      "Python path additions: ['../src/data_pipline', '../src/EU_XML_data_loader']\n"
     ]
    }
   ],
   "source": [
    "# Data Pipeline - Extract EPO Archives\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the data_pipeline to path\n",
    "sys.path.append('../src/data_pipline')\n",
    "sys.path.append('../src/EU_XML_data_loader')\n",
    "\n",
    "print(\"📁 Setting up paths...\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Python path additions: {sys.path[-2:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "267a52ce-7b0a-47ec-9d16-a7ce67b66c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully imported pipeline modules\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "try:\n",
    "    from data_pipline import DataPipeline\n",
    "    from load_raw_data import extract_epo_archives\n",
    "    print(\"✅ Successfully imported pipeline modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import error: {e}\")\n",
    "    print(\"🔧 Please ensure the following files exist:\")\n",
    "    print(\"   - src/data_pipline/data_pipline.py\")\n",
    "    print(\"   - src/EU_XML_data_loader/load_raw_data.py\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe59bd6f-26fc-4b44-b507-39f95ce420e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epo_data_pipeline_updated():\n",
    "    \"\"\"\n",
    "    Updated EPO data pipeline function that handles the correct archive structure\n",
    "    \"\"\"\n",
    "    print(\"🚀 Starting Updated EPO Data Pipeline...\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize the data pipeline\n",
    "        pipeline = DataPipeline()\n",
    "        print(\"✅ Data pipeline initialized\")\n",
    "        \n",
    "        # Check what archives are available\n",
    "        print(\"\\n🔍 Checking EPO archive structure...\")\n",
    "        archive_info = pipeline.check_epo_archive_structure()\n",
    "        \n",
    "        if archive_info[\"total\"] == 0:\n",
    "            print(\"❌ No EPO archives found in data/archive/EPO\")\n",
    "            print(\"📁 Expected structure: data/archive/EPO/EPRTBJV*/DOC/*/\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"✅ Found {archive_info['total']} EPO archive folders:\")\n",
    "        for archive in archive_info[\"archives\"]:\n",
    "            print(f\"  📦 {archive['name']}\")\n",
    "            print(f\"    📂 DOC folder: {archive['doc_folder']}\")\n",
    "            print(f\"    📁 Subfolders: {len(archive['subfolders'])}\")\n",
    "            \n",
    "            # Show subfolder details\n",
    "            for subfolder in archive['subfolders']:\n",
    "                zip_count = len(list(subfolder.glob(\"*.zip\")))\n",
    "                print(f\"      📋 {subfolder.name}: {zip_count} ZIP files\")\n",
    "        \n",
    "        # Show total files to process\n",
    "        total_zips = sum(archive['zip_count'] for archive in archive_info['archives'])\n",
    "        print(f\"\\n📊 Total ZIP files to process: {total_zips}\")\n",
    "        \n",
    "        # Run the extraction\n",
    "        print(\"\\n🔄 Starting extraction process...\")\n",
    "        result = pipeline.extract_epo_data(verbose=True)\n",
    "        \n",
    "        print(\"\\n✅ EPO Data Pipeline completed!\")\n",
    "        print(f\"📊 Final Results:\")\n",
    "        print(f\"   Archives processed: {result.get('archives_processed', 0)}\")\n",
    "        print(f\"   Files extracted: {result.get('files_extracted', 0)}\")\n",
    "        print(f\"   XML files: {result.get('xml_files', 0)}\")\n",
    "        print(f\"   PDF files: {result.get('pdf_files', 0)}\")\n",
    "        print(f\"   Errors: {result.get('errors', 0)}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in EPO Data Pipeline: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa298b3-3040-48d4-b483-c1c71b398532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 13:44:33,835 - INFO - Data pipeline initialized with base directory: /app/notebooks/..\n",
      "2025-06-16 13:44:33,837 - INFO - Checking EPO archive structure...\n",
      "2025-06-16 13:44:33,897 - INFO - Found archive: EPRTBJV2025000024001001 with 5461 ZIP files\n",
      "2025-06-16 13:44:33,909 - INFO - Starting EPO data extraction...\n",
      "2025-06-16 13:44:33,910 - INFO - Checking EPO archive structure...\n",
      "2025-06-16 13:44:33,923 - INFO - Found archive: EPRTBJV2025000024001001 with 5461 ZIP files\n",
      "2025-06-16 13:44:33,925 - INFO - Found 0 ZIP files in /app/notebooks/../data/archive/EPO/EPRTBJV2025000024001001\n",
      "2025-06-16 13:44:33,925 - WARNING - No ZIP files found in archive directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Updated EPO Data Pipeline...\n",
      "✅ Data pipeline initialized\n",
      "\n",
      "🔍 Checking EPO archive structure...\n",
      "✅ Found 1 EPO archive folders:\n",
      "  📦 EPRTBJV2025000024001001\n",
      "    📂 DOC folder: /app/notebooks/../data/archive/EPO/EPRTBJV2025000024001001/DOC\n",
      "    📁 Subfolders: 11\n",
      "      📋 EPW1B9: 2 ZIP files\n",
      "      📋 EPW1A8: 2 ZIP files\n",
      "      📋 EPW1A9: 2 ZIP files\n",
      "      📋 EPW1B8: 29 ZIP files\n",
      "      📋 EPNWB1: 1673 ZIP files\n",
      "      📋 EPNWA1: 2975 ZIP files\n",
      "      📋 EPW2B9: 1 ZIP files\n",
      "      📋 EPW2A8: 1 ZIP files\n",
      "      📋 EPNWB2: 32 ZIP files\n",
      "      📋 EPNWA3: 310 ZIP files\n",
      "      📋 EPNWA2: 434 ZIP files\n",
      "\n",
      "📊 Total ZIP files to process: 5461\n",
      "\n",
      "🔄 Starting extraction process...\n",
      "🔍 Found 1 EPO archive folders\n",
      "  📦 EPRTBJV2025000024001001: 5461 ZIP files\n",
      "\n",
      "🚀 Processing archive: EPRTBJV2025000024001001\n",
      "✅ Completed archive: EPRTBJV2025000024001001\n",
      "\n",
      "📊 EPO Extraction Summary:\n",
      "  📁 Archives processed: 0\n",
      "  📄 Files extracted: 0\n",
      "  📋 XML files: 0\n",
      "  📑 PDF files: 0\n",
      "  ❌ Errors: 0\n",
      "\n",
      "✅ EPO Data Pipeline completed!\n",
      "📊 Final Results:\n",
      "   Archives processed: 0\n",
      "   Files extracted: 0\n",
      "   XML files: 0\n",
      "   PDF files: 0\n",
      "   Errors: 0\n",
      "\n",
      "🎉 Pipeline execution completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Run the EPO data pipeline\n",
    "result = run_epo_data_pipeline_updated()\n",
    "\n",
    "if result:\n",
    "    print(\"\\n🎉 Pipeline execution completed successfully!\")\n",
    "else:\n",
    "    print(\"\\n❌ Pipeline execution failed or was cancelled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e57c8e01-9569-4a2c-8deb-ffae154806fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Debugging archive structure...\n",
      "📁 Checking folder: ../data/archive/EPO/EPRTBJV2025000024001001/DOC/EPNWA1\n",
      "📦 Found 2975 ZIP files\n",
      "\n",
      "🔍 Examining: EP24217419NWA1.zip\n",
      "📋 Files inside ZIP (8 total):\n",
      "   📄 XML files: 2\n",
      "   📑 PDF files: 1\n",
      "     1. EP24217419NWA1.xml\n",
      "     2. TOC.xml\n",
      "     3. EP24217419NWA1.pdf\n",
      "     4. imgaf001.tif\n",
      "     5. imgf0001.tif\n",
      "     6. imgf0002.tif\n",
      "     7. srep0001.tif\n",
      "     8. srep0002.tif\n"
     ]
    }
   ],
   "source": [
    "# Add this debugging cell to understand what's happening\n",
    "def debug_archive_structure():\n",
    "    \"\"\"Debug the archive structure to see what's inside the ZIP files\"\"\"\n",
    "    import zipfile\n",
    "    from pathlib import Path\n",
    "    \n",
    "    archive_path = Path(\"../data/archive/EPO/EPRTBJV2025000024001001\")\n",
    "    \n",
    "    print(\"🔍 Debugging archive structure...\")\n",
    "    \n",
    "    # Check one subfolder in detail\n",
    "    epnwa1_folder = archive_path / \"DOC\" / \"EPNWA1\"\n",
    "    if epnwa1_folder.exists():\n",
    "        zip_files = list(epnwa1_folder.glob(\"*.zip\"))\n",
    "        print(f\"📁 Checking folder: {epnwa1_folder}\")\n",
    "        print(f\"📦 Found {len(zip_files)} ZIP files\")\n",
    "        \n",
    "        if zip_files:\n",
    "            # Examine the first ZIP file\n",
    "            first_zip = zip_files[0]\n",
    "            print(f\"\\n🔍 Examining: {first_zip.name}\")\n",
    "            \n",
    "            try:\n",
    "                with zipfile.ZipFile(first_zip, 'r') as zip_ref:\n",
    "                    file_list = zip_ref.namelist()\n",
    "                    print(f\"📋 Files inside ZIP ({len(file_list)} total):\")\n",
    "                    \n",
    "                    xml_files = [f for f in file_list if f.endswith('.xml')]\n",
    "                    pdf_files = [f for f in file_list if f.endswith('.pdf')]\n",
    "                    \n",
    "                    print(f\"   📄 XML files: {len(xml_files)}\")\n",
    "                    print(f\"   📑 PDF files: {len(pdf_files)}\")\n",
    "                    \n",
    "                    # Show first few files\n",
    "                    for i, file_name in enumerate(file_list[:10]):\n",
    "                        print(f\"     {i+1}. {file_name}\")\n",
    "                    \n",
    "                    if len(file_list) > 10:\n",
    "                        print(f\"     ... and {len(file_list) - 10} more files\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error reading ZIP file: {e}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"❌ EPNWA1 folder not found at: {epnwa1_folder}\")\n",
    "\n",
    "# Run the debug function\n",
    "debug_archive_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f359016c-a56a-4a69-8f7f-b1dea96c6496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing extraction of: EP24217419NWA1.zip\n",
      "✅ Extraction successful!\n",
      "📁 Total extracted files: 8\n",
      "📄 XML files: 2\n",
      "📑 PDF files: 1\n",
      "\n",
      "📂 Extracted structure:\n",
      "   📄 srep0001.tif\n",
      "   📄 EP24217419NWA1.xml\n",
      "   📄 EP24217419NWA1.pdf\n",
      "   📄 imgaf001.tif\n",
      "   📄 imgf0001.tif\n",
      "   📄 imgf0002.tif\n",
      "   📄 TOC.xml\n",
      "   📄 srep0002.tif\n"
     ]
    }
   ],
   "source": [
    "# Also add this cell to check if the extraction is working at a lower level\n",
    "def test_single_zip_extraction():\n",
    "    \"\"\"Test extracting a single ZIP file manually\"\"\"\n",
    "    import zipfile\n",
    "    import tempfile\n",
    "    from pathlib import Path\n",
    "    \n",
    "    archive_path = Path(\"../data/archive/EPO/EPRTBJV2025000024001001\")\n",
    "    epnwa1_folder = archive_path / \"DOC\" / \"EPNWA1\"\n",
    "    \n",
    "    if not epnwa1_folder.exists():\n",
    "        print(f\"❌ Folder not found: {epnwa1_folder}\")\n",
    "        return\n",
    "    \n",
    "    zip_files = list(epnwa1_folder.glob(\"*.zip\"))\n",
    "    if not zip_files:\n",
    "        print(\"❌ No ZIP files found\")\n",
    "        return\n",
    "    \n",
    "    # Try to extract the first ZIP file\n",
    "    test_zip = zip_files[0]\n",
    "    print(f\"🧪 Testing extraction of: {test_zip.name}\")\n",
    "    \n",
    "    try:\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            temp_path = Path(temp_dir)\n",
    "            \n",
    "            with zipfile.ZipFile(test_zip, 'r') as zip_ref:\n",
    "                zip_ref.extractall(temp_path)\n",
    "            \n",
    "            # Check what was extracted\n",
    "            extracted_files = list(temp_path.rglob(\"*\"))\n",
    "            xml_files = [f for f in extracted_files if f.suffix == '.xml']\n",
    "            pdf_files = [f for f in extracted_files if f.suffix == '.pdf']\n",
    "            \n",
    "            print(f\"✅ Extraction successful!\")\n",
    "            print(f\"📁 Total extracted files: {len(extracted_files)}\")\n",
    "            print(f\"📄 XML files: {len(xml_files)}\")\n",
    "            print(f\"📑 PDF files: {len(pdf_files)}\")\n",
    "            \n",
    "            # Show file structure\n",
    "            print(\"\\n📂 Extracted structure:\")\n",
    "            for file_path in extracted_files[:15]:  # Show first 15\n",
    "                if file_path.is_file():\n",
    "                    print(f\"   📄 {file_path.relative_to(temp_path)}\")\n",
    "                elif file_path.is_dir():\n",
    "                    print(f\"   📁 {file_path.relative_to(temp_path)}/\")\n",
    "            \n",
    "            if len(extracted_files) > 15:\n",
    "                print(f\"   ... and {len(extracted_files) - 15} more\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Extraction failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Run the test\n",
    "test_single_zip_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03563e1f-bc4c-4446-8abf-bd6f0ed66f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Working EPO Extraction\n",
      "📂 Source: ../data/archive/EPO/EPRTBJV2025000024001001\n",
      "📁 Output: ../data/raw/EPO/EPRTBJV2025000024001001\n",
      "\n",
      "📁 Processing subfolder: EPW1B9\n",
      "📦 Found 2 ZIP files\n",
      "  🔄 Processing 1/2: EP22169662W1B9.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 3 TIF, 0 other\n",
      "  🔄 Processing 2/2: EP13899497W1B9.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 25 TIF, 0 other\n",
      "\n",
      "📁 Processing subfolder: EPW1A8\n",
      "📦 Found 2 ZIP files\n",
      "  🔄 Processing 1/2: EP23166881W1A8.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 1 TIF, 0 other\n",
      "  🔄 Processing 2/2: EP23205649W1A8.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 1 TIF, 0 other\n",
      "\n",
      "📁 Processing subfolder: EPW1A9\n",
      "📦 Found 2 ZIP files\n",
      "  🔄 Processing 1/2: EP23204356W1A9.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 11 TIF, 0 other\n",
      "  🔄 Processing 2/2: EP24185369W1A9.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 3 TIF, 0 other\n",
      "\n",
      "📁 Processing subfolder: EPW1B8\n",
      "📦 Found 29 ZIP files\n",
      "  🔄 Processing 1/10: EP22732225W1B8.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 2/10: EP21207842W1B8.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 3/10: EP19886818W1B8.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 4/10: EP19849370W1B8.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 5/10: EP19715705W1B8.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 6/10: EP22204324W1B8.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 7/10: EP19742218W1B8.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 8/10: EP21718490W1B8.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 9/10: EP18784075W1B8.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 10/10: EP19820697W1B8.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 0 TIF, 0 other\n",
      "  ⏩ Processed 10 of 29 files (limited for testing)\n",
      "\n",
      "📁 Processing subfolder: EPNWB1\n",
      "📦 Found 1673 ZIP files\n",
      "  🔄 Processing 1/10: EP22891758NWB1.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 4 TIF, 0 other\n",
      "  🔄 Processing 2/10: EP16866015NWB1.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 12 TIF, 0 other\n",
      "  🔄 Processing 3/10: EP20703357NWB1.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 11 TIF, 0 other\n",
      "  🔄 Processing 4/10: EP23203787NWB1.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 1 TIF, 0 other\n",
      "  🔄 Processing 5/10: EP22725842NWB1.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 3 TIF, 0 other\n",
      "  🔄 Processing 6/10: EP20769410NWB1.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 8 TIF, 0 other\n",
      "  🔄 Processing 7/10: EP19838944NWB1.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 5 TIF, 0 other\n",
      "  🔄 Processing 8/10: EP20893135NWB1.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 18 TIF, 0 other\n",
      "  🔄 Processing 9/10: EP21197969NWB1.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 1 TIF, 0 other\n",
      "  🔄 Processing 10/10: EP24172810NWB1.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 2 TIF, 0 other\n",
      "  ⏩ Processed 10 of 1673 files (limited for testing)\n",
      "\n",
      "📁 Processing subfolder: EPNWA1\n",
      "📦 Found 2975 ZIP files\n",
      "  🔄 Processing 1/10: EP24217419NWA1.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 5 TIF, 0 other\n",
      "  🔄 Processing 2/10: EP23748930NWA1.zip\n",
      "    ✅ Extracted: 2 XML, 0 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 3/10: EP23738142NWA1.zip\n",
      "    ✅ Extracted: 2 XML, 0 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 4/10: EP23754359NWA1.zip\n",
      "    ✅ Extracted: 2 XML, 0 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 5/10: EP23850490NWA1.zip\n",
      "    ✅ Extracted: 2 XML, 0 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 6/10: EP24215311NWA1.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 14 TIF, 0 other\n",
      "  🔄 Processing 7/10: EP23895724NWA1.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 23 TIF, 0 other\n",
      "  🔄 Processing 8/10: EP23817256NWA1.zip\n",
      "    ✅ Extracted: 2 XML, 0 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 9/10: EP24216746NWA1.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 7 TIF, 0 other\n",
      "  🔄 Processing 10/10: EP23750620NWA1.zip\n",
      "    ✅ Extracted: 2 XML, 0 PDF, 0 TIF, 0 other\n",
      "  ⏩ Processed 10 of 2975 files (limited for testing)\n",
      "\n",
      "📁 Processing subfolder: EPW2B9\n",
      "📦 Found 1 ZIP files\n",
      "  🔄 Processing 1/1: EP18754030W2B9.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 9 TIF, 0 other\n",
      "\n",
      "📁 Processing subfolder: EPW2A8\n",
      "📦 Found 1 ZIP files\n",
      "  🔄 Processing 1/1: EP24158913W2A8.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 1 TIF, 0 other\n",
      "\n",
      "📁 Processing subfolder: EPNWB2\n",
      "📦 Found 32 ZIP files\n",
      "  🔄 Processing 1/10: EP16784818NWB2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 4 TIF, 0 other\n",
      "  🔄 Processing 2/10: EP15739626NWB2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 1 TIF, 0 other\n",
      "  🔄 Processing 3/10: EP17203505NWB2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 2 TIF, 0 other\n",
      "  🔄 Processing 4/10: EP19734910NWB2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 8 TIF, 0 other\n",
      "  🔄 Processing 5/10: EP14772312NWB2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 3 TIF, 0 other\n",
      "  🔄 Processing 6/10: EP19734909NWB2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 8 TIF, 0 other\n",
      "  🔄 Processing 7/10: EP18787888NWB2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 8 TIF, 0 other\n",
      "  🔄 Processing 8/10: EP16858552NWB2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 10 TIF, 0 other\n",
      "  🔄 Processing 9/10: EP09800007NWB2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 1 TIF, 0 other\n",
      "  🔄 Processing 10/10: EP19734827NWB2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 4 TIF, 0 other\n",
      "  ⏩ Processed 10 of 32 files (limited for testing)\n",
      "\n",
      "📁 Processing subfolder: EPNWA3\n",
      "📦 Found 310 ZIP files\n",
      "  🔄 Processing 1/10: EP24221135NWA3.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 3 TIF, 0 other\n",
      "  🔄 Processing 2/10: EP24213713NWA3.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 3 TIF, 0 other\n",
      "  🔄 Processing 3/10: EP25158136NWA3.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 4 TIF, 0 other\n",
      "  🔄 Processing 4/10: EP24210191NWA3.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 2 TIF, 0 other\n",
      "  🔄 Processing 5/10: EP25152876NWA3.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 3 TIF, 0 other\n",
      "  🔄 Processing 6/10: EP24221480NWA3.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 3 TIF, 0 other\n",
      "  🔄 Processing 7/10: EP24206691NWA3.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 2 TIF, 0 other\n",
      "  🔄 Processing 8/10: EP25165220NWA3.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 4 TIF, 0 other\n",
      "  🔄 Processing 9/10: EP25167215NWA3.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 2 TIF, 0 other\n",
      "  🔄 Processing 10/10: EP25155276NWA3.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 2 TIF, 0 other\n",
      "  ⏩ Processed 10 of 310 files (limited for testing)\n",
      "\n",
      "📁 Processing subfolder: EPNWA2\n",
      "📦 Found 434 ZIP files\n",
      "  🔄 Processing 1/10: EP25166960NWA2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 37 TIF, 0 other\n",
      "  🔄 Processing 2/10: EP23851030NWA2.zip\n",
      "    ✅ Extracted: 2 XML, 0 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 3/10: EP23850990NWA2.zip\n",
      "    ✅ Extracted: 2 XML, 0 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 4/10: EP24200553NWA2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 14 TIF, 0 other\n",
      "  🔄 Processing 5/10: EP24212579NWA2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 16 TIF, 0 other\n",
      "  🔄 Processing 6/10: EP25172005NWA2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 36 TIF, 0 other\n",
      "  🔄 Processing 7/10: EP25153748NWA2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 4 TIF, 0 other\n",
      "  🔄 Processing 8/10: EP23850583NWA2.zip\n",
      "    ✅ Extracted: 2 XML, 0 PDF, 0 TIF, 0 other\n",
      "  🔄 Processing 9/10: EP25164652NWA2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 12 TIF, 0 other\n",
      "  🔄 Processing 10/10: EP24216541NWA2.zip\n",
      "    ✅ Extracted: 2 XML, 1 PDF, 9 TIF, 0 other\n",
      "  ⏩ Processed 10 of 434 files (limited for testing)\n",
      "\n",
      "📊 Extraction Results:\n",
      "   Subfolders processed: 11\n",
      "   ZIP files processed: 68\n",
      "   📄 XML files: 136\n",
      "   📑 PDF files: 59\n",
      "   🖼️  TIF files: 373\n",
      "   📋 Other files: 0\n",
      "   ❌ Errors: 0\n",
      "\n",
      "📂 Output structure created at: ../data/raw/EPO/EPRTBJV2025000024001001\n"
     ]
    }
   ],
   "source": [
    "# Add this new cell to fix the extraction issue\n",
    "def working_epo_extraction():\n",
    "    \"\"\"\n",
    "    Working EPO extraction function that properly handles the ZIP structure\n",
    "    \"\"\"\n",
    "    import zipfile\n",
    "    import shutil\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Paths\n",
    "    archive_base = Path(\"../data/archive/EPO/EPRTBJV2025000024001001\")\n",
    "    output_base = Path(\"../data/raw/EPO/EPRTBJV2025000024001001\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_base.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(f\"🚀 Starting Working EPO Extraction\")\n",
    "    print(f\"📂 Source: {archive_base}\")\n",
    "    print(f\"📁 Output: {output_base}\")\n",
    "    \n",
    "    doc_folder = archive_base / \"DOC\"\n",
    "    if not doc_folder.exists():\n",
    "        print(f\"❌ DOC folder not found: {doc_folder}\")\n",
    "        return\n",
    "    \n",
    "    stats = {\n",
    "        'zip_files_processed': 0,\n",
    "        'xml_files': 0,\n",
    "        'pdf_files': 0,\n",
    "        'tif_files': 0,\n",
    "        'other_files': 0,\n",
    "        'errors': 0,\n",
    "        'subfolders_processed': 0\n",
    "    }\n",
    "    \n",
    "    # Process each subfolder\n",
    "    for subfolder in doc_folder.iterdir():\n",
    "        if not subfolder.is_dir():\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n📁 Processing subfolder: {subfolder.name}\")\n",
    "        subfolder_output = output_base / subfolder.name\n",
    "        subfolder_output.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        zip_files = list(subfolder.glob(\"*.zip\"))\n",
    "        print(f\"📦 Found {len(zip_files)} ZIP files\")\n",
    "        \n",
    "        # Process all ZIP files (or limit for testing)\n",
    "        process_count = min(len(zip_files), 10)  # Process first 10 per folder for testing\n",
    "        \n",
    "        for i, zip_file in enumerate(zip_files[:process_count], 1):\n",
    "            try:\n",
    "                print(f\"  🔄 Processing {i}/{process_count}: {zip_file.name}\")\n",
    "                \n",
    "                # Create individual folder for each ZIP file\n",
    "                zip_output_dir = subfolder_output / zip_file.stem\n",
    "                zip_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "                    # Extract all files\n",
    "                    zip_ref.extractall(zip_output_dir)\n",
    "                    \n",
    "                    # Count different file types\n",
    "                    extracted_files = list(zip_output_dir.rglob(\"*\"))\n",
    "                    \n",
    "                    zip_xml = len([f for f in extracted_files if f.suffix.lower() == '.xml' and f.is_file()])\n",
    "                    zip_pdf = len([f for f in extracted_files if f.suffix.lower() == '.pdf' and f.is_file()])\n",
    "                    zip_tif = len([f for f in extracted_files if f.suffix.lower() == '.tif' and f.is_file()])\n",
    "                    zip_other = len([f for f in extracted_files if f.is_file() and f.suffix.lower() not in ['.xml', '.pdf', '.tif']])\n",
    "                    \n",
    "                    stats['xml_files'] += zip_xml\n",
    "                    stats['pdf_files'] += zip_pdf\n",
    "                    stats['tif_files'] += zip_tif\n",
    "                    stats['other_files'] += zip_other\n",
    "                    stats['zip_files_processed'] += 1\n",
    "                    \n",
    "                    print(f\"    ✅ Extracted: {zip_xml} XML, {zip_pdf} PDF, {zip_tif} TIF, {zip_other} other\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    ❌ Error with {zip_file.name}: {e}\")\n",
    "                stats['errors'] += 1\n",
    "        \n",
    "        stats['subfolders_processed'] += 1\n",
    "        \n",
    "        if len(zip_files) > process_count:\n",
    "            print(f\"  ⏩ Processed {process_count} of {len(zip_files)} files (limited for testing)\")\n",
    "    \n",
    "    print(f\"\\n📊 Extraction Results:\")\n",
    "    print(f\"   Subfolders processed: {stats['subfolders_processed']}\")\n",
    "    print(f\"   ZIP files processed: {stats['zip_files_processed']}\")\n",
    "    print(f\"   📄 XML files: {stats['xml_files']}\")\n",
    "    print(f\"   📑 PDF files: {stats['pdf_files']}\")\n",
    "    print(f\"   🖼️  TIF files: {stats['tif_files']}\")\n",
    "    print(f\"   📋 Other files: {stats['other_files']}\")\n",
    "    print(f\"   ❌ Errors: {stats['errors']}\")\n",
    "    \n",
    "    # Show output structure\n",
    "    print(f\"\\n📂 Output structure created at: {output_base}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Run the working extraction\n",
    "extraction_stats = working_epo_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f08bbc02-30d9-4b6e-a348-bba51088e6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ This will process ALL 5461 ZIP files and may take 30-60 minutes\n",
      "🎯 Only PDF and XML files will be kept\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to proceed? (y/N):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Optimized EPO Extraction (PDF & XML only)\n",
      "📂 Source: ../data/archive/EPO/EPRTBJV2025000024001001\n",
      "📁 Output: ../data/raw/EPO/EPRTBJV2025000024001001\n",
      "📅 Start time: 13:57:47\n",
      "❌ DOC folder not found: ../data/archive/EPO/EPRTBJV2025000024001001/DOC\n"
     ]
    }
   ],
   "source": [
    "def optimized_epo_extraction():\n",
    "    \"\"\"\n",
    "    Optimized EPO extraction function that:\n",
    "    - Processes ALL ZIP files (not just first 10)\n",
    "    - Extracts only PDF and XML files directly\n",
    "    - No temporary folders or intermediate storage\n",
    "    - Clean, efficient output structure\n",
    "    \"\"\"\n",
    "    import zipfile\n",
    "    import shutil\n",
    "    from pathlib import Path\n",
    "    import time\n",
    "    \n",
    "    # Paths\n",
    "    archive_base = Path(\"../data/archive/EPO/EPRTBJV2025000024001001\")\n",
    "    output_base = Path(\"../data/raw/EPO/EPRTBJV2025000024001001\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_base.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(f\"🚀 Starting Optimized EPO Extraction (PDF & XML only)\")\n",
    "    print(f\"📂 Source: {archive_base}\")\n",
    "    print(f\"📁 Output: {output_base}\")\n",
    "    print(f\"📅 Start time: {time.strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    doc_folder = archive_base / \"DOC\"\n",
    "    if not doc_folder.exists():\n",
    "        print(f\"❌ DOC folder not found: {doc_folder}\")\n",
    "        return None\n",
    "    \n",
    "    stats = {\n",
    "        'zip_files_processed': 0,\n",
    "        'xml_files_extracted': 0,\n",
    "        'pdf_files_extracted': 0,\n",
    "        'files_skipped': 0,\n",
    "        'errors': 0,\n",
    "        'subfolders_processed': 0,\n",
    "        'total_zip_files': 0\n",
    "    }\n",
    "    \n",
    "    # Count total ZIP files first\n",
    "    for subfolder in doc_folder.iterdir():\n",
    "        if subfolder.is_dir():\n",
    "            zip_count = len(list(subfolder.glob(\"*.zip\")))\n",
    "            stats['total_zip_files'] += zip_count\n",
    "    \n",
    "    print(f\"📊 Total ZIP files to process: {stats['total_zip_files']}\")\n",
    "    \n",
    "    # Process each subfolder\n",
    "    for subfolder in doc_folder.iterdir():\n",
    "        if not subfolder.is_dir():\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n📁 Processing subfolder: {subfolder.name}\")\n",
    "        subfolder_output = output_base / subfolder.name\n",
    "        subfolder_output.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        zip_files = list(subfolder.glob(\"*.zip\"))\n",
    "        print(f\"📦 Processing {len(zip_files)} ZIP files...\")\n",
    "        \n",
    "        # Process ALL ZIP files\n",
    "        for i, zip_file in enumerate(zip_files, 1):\n",
    "            try:\n",
    "                if i % 100 == 0 or i == 1:  # Progress update every 100 files\n",
    "                    print(f\"  🔄 Processing {i}/{len(zip_files)}: {zip_file.name}\")\n",
    "                \n",
    "                # Create individual folder for each ZIP file\n",
    "                zip_output_dir = subfolder_output / zip_file.stem\n",
    "                zip_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                zip_xml_count = 0\n",
    "                zip_pdf_count = 0\n",
    "                zip_skipped = 0\n",
    "                \n",
    "                with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "                    # Get all file names in the ZIP\n",
    "                    all_files = zip_ref.namelist()\n",
    "                    \n",
    "                    # Filter for only PDF and XML files\n",
    "                    target_files = [f for f in all_files if f.lower().endswith(('.pdf', '.xml'))]\n",
    "                    zip_skipped = len(all_files) - len(target_files)\n",
    "                    \n",
    "                    # Extract only PDF and XML files\n",
    "                    for file_name in target_files:\n",
    "                        try:\n",
    "                            # Extract individual file\n",
    "                            zip_ref.extract(file_name, zip_output_dir)\n",
    "                            \n",
    "                            # Count by type\n",
    "                            if file_name.lower().endswith('.xml'):\n",
    "                                zip_xml_count += 1\n",
    "                            elif file_name.lower().endswith('.pdf'):\n",
    "                                zip_pdf_count += 1\n",
    "                                \n",
    "                        except Exception as file_error:\n",
    "                            print(f\"    ⚠️ Error extracting {file_name}: {file_error}\")\n",
    "                            continue\n",
    "                \n",
    "                # Update global stats\n",
    "                stats['xml_files_extracted'] += zip_xml_count\n",
    "                stats['pdf_files_extracted'] += zip_pdf_count\n",
    "                stats['files_skipped'] += zip_skipped\n",
    "                stats['zip_files_processed'] += 1\n",
    "                \n",
    "                # Show progress for first few files or every 100th\n",
    "                if i <= 5 or i % 100 == 0:\n",
    "                    print(f\"    ✅ {zip_file.name}: {zip_xml_count} XML, {zip_pdf_count} PDF, {zip_skipped} skipped\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    ❌ Error with {zip_file.name}: {e}\")\n",
    "                stats['errors'] += 1\n",
    "        \n",
    "        stats['subfolders_processed'] += 1\n",
    "        print(f\"  ✅ Completed {subfolder.name}: {len(zip_files)} ZIP files processed\")\n",
    "    \n",
    "    # Final results\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(f\"🎉 Optimized EPO Extraction Completed!\")\n",
    "    print(f\"📅 End time: {time.strftime('%H:%M:%S')}\")\n",
    "    print(f\"⏱️ Total time: {total_time:.2f} seconds ({total_time/60:.1f} minutes)\")\n",
    "    print(f\"\\n📊 Final Statistics:\")\n",
    "    print(f\"   Subfolders processed: {stats['subfolders_processed']}\")\n",
    "    print(f\"   ZIP files processed: {stats['zip_files_processed']}/{stats['total_zip_files']}\")\n",
    "    print(f\"   📄 XML files extracted: {stats['xml_files_extracted']}\")\n",
    "    print(f\"   📑 PDF files extracted: {stats['pdf_files_extracted']}\")\n",
    "    print(f\"   📋 Total files extracted: {stats['xml_files_extracted'] + stats['pdf_files_extracted']}\")\n",
    "    print(f\"   ⏩ Files skipped (non-PDF/XML): {stats['files_skipped']}\")\n",
    "    print(f\"   ❌ Errors: {stats['errors']}\")\n",
    "    print(f\"   📈 Processing rate: {stats['zip_files_processed']/(total_time/60):.1f} ZIP files/minute\")\n",
    "    \n",
    "    print(f\"\\n📂 Clean output structure created at: {output_base}\")\n",
    "    print(f\"   📁 Contains only PDF and XML files\")\n",
    "    print(f\"   🗂️ Organized by: Archive/Subfolder/ZipName/files\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Run the optimized extraction\n",
    "print(\"⚠️ This will process ALL 5461 ZIP files and may take 30-60 minutes\")\n",
    "print(\"🎯 Only PDF and XML files will be kept\")\n",
    "proceed = input(\"Do you want to proceed? (y/N): \")\n",
    "\n",
    "if proceed.lower() == 'y':\n",
    "    final_stats = optimized_epo_extraction()\n",
    "else:\n",
    "    print(\"❌ Extraction cancelled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8daa53b5-f353-413a-b2da-d7b290ce5edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 This will process ALL EPO archives in your archive/EPO directory:\n",
      "  - EPRTBJV2025000021001001.zip\n",
      "  - EPRTBJV2025000022001001.zip\n",
      "  - EPRTBJV2025000023001001.zip\n",
      "  - EPRTBJV2025000024001001.zip\n",
      "  - EPRTBJV2025000024001001/ (already extracted)\n",
      "\n",
      "⚠️ This may take several hours depending on the total number of ZIP files\n",
      "🎯 Only PDF and XML files will be kept\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to process ALL EPO archives? (y/N):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Processing ALL EPO Archives\n",
      "📂 Source directory: ../data/archive/EPO\n",
      "📁 Output directory: ../data/raw/EPO\n",
      "📅 Start time: 14:04:10\n",
      "============================================================\n",
      "🔍 Found 5 EPO archives to process:\n",
      "  📦 EPRTBJV2025000021001001 (main_zip)\n",
      "  📦 EPRTBJV2025000024001001 (directory)\n",
      "  📦 EPRTBJV2025000023001001 (main_zip)\n",
      "  📦 EPRTBJV2025000022001001 (main_zip)\n",
      "  📦 EPRTBJV2025000024001001 (main_zip)\n",
      "\n",
      "============================================================\n",
      "\n",
      "[1/5] Processing: EPRTBJV2025000021001001\n",
      "  🔄 Extracting main ZIP: EPRTBJV2025000021001001.zip\n",
      "    📂 Processing DOC folder: /tmp/tmpabl5zryz/DOC\n",
      "    📁 Found 9 subfolders\n",
      "      📦 EPW1B8: Processing 24 ZIP files\n",
      "      ✅ Completed EPW1B8: 24 ZIP files\n",
      "      📦 EPW1B9: Processing 4 ZIP files\n",
      "      ✅ Completed EPW1B9: 4 ZIP files\n",
      "      📦 EPW1A9: Processing 1 ZIP files\n",
      "      ✅ Completed EPW1A9: 1 ZIP files\n",
      "      📦 EPNWA2: Processing 430 ZIP files\n",
      "        🔄 Progress: 100/430\n",
      "        🔄 Progress: 200/430\n",
      "        🔄 Progress: 300/430\n",
      "        🔄 Progress: 400/430\n",
      "      ✅ Completed EPNWA2: 430 ZIP files\n",
      "      📦 EPNWB1: Processing 2128 ZIP files\n",
      "        🔄 Progress: 100/2128\n",
      "        🔄 Progress: 200/2128\n",
      "        🔄 Progress: 300/2128\n",
      "        🔄 Progress: 400/2128\n",
      "        🔄 Progress: 500/2128\n",
      "        🔄 Progress: 600/2128\n",
      "        🔄 Progress: 700/2128\n",
      "        🔄 Progress: 800/2128\n",
      "        🔄 Progress: 900/2128\n",
      "        🔄 Progress: 1000/2128\n",
      "        🔄 Progress: 1100/2128\n",
      "        🔄 Progress: 1200/2128\n",
      "        🔄 Progress: 1300/2128\n",
      "        🔄 Progress: 1400/2128\n",
      "        🔄 Progress: 1500/2128\n",
      "        🔄 Progress: 1600/2128\n",
      "        🔄 Progress: 1700/2128\n",
      "        🔄 Progress: 1800/2128\n",
      "        🔄 Progress: 1900/2128\n",
      "        🔄 Progress: 2000/2128\n",
      "        🔄 Progress: 2100/2128\n",
      "      ✅ Completed EPNWB1: 2128 ZIP files\n",
      "      📦 EPNWA1: Processing 3135 ZIP files\n",
      "        🔄 Progress: 100/3135\n",
      "        🔄 Progress: 200/3135\n",
      "        🔄 Progress: 300/3135\n",
      "        🔄 Progress: 400/3135\n",
      "        🔄 Progress: 500/3135\n",
      "        🔄 Progress: 600/3135\n",
      "        🔄 Progress: 700/3135\n",
      "        🔄 Progress: 800/3135\n",
      "        🔄 Progress: 900/3135\n",
      "        🔄 Progress: 1000/3135\n",
      "        🔄 Progress: 1100/3135\n",
      "        🔄 Progress: 1200/3135\n",
      "        🔄 Progress: 1300/3135\n",
      "        🔄 Progress: 1400/3135\n",
      "        🔄 Progress: 1500/3135\n",
      "        🔄 Progress: 1600/3135\n",
      "        🔄 Progress: 1700/3135\n",
      "        🔄 Progress: 1800/3135\n",
      "        🔄 Progress: 1900/3135\n",
      "        🔄 Progress: 2000/3135\n",
      "        🔄 Progress: 2100/3135\n",
      "        🔄 Progress: 2200/3135\n",
      "        🔄 Progress: 2300/3135\n",
      "        🔄 Progress: 2400/3135\n",
      "        🔄 Progress: 2500/3135\n",
      "        🔄 Progress: 2600/3135\n",
      "        🔄 Progress: 2700/3135\n",
      "        🔄 Progress: 2800/3135\n",
      "        🔄 Progress: 2900/3135\n",
      "        🔄 Progress: 3000/3135\n",
      "        🔄 Progress: 3100/3135\n",
      "      ✅ Completed EPNWA1: 3135 ZIP files\n",
      "      📦 EPNWB2: Processing 34 ZIP files\n",
      "      ✅ Completed EPNWB2: 34 ZIP files\n",
      "      📦 EPW1A8: Processing 1 ZIP files\n",
      "      ✅ Completed EPW1A8: 1 ZIP files\n",
      "      📦 EPNWA3: Processing 329 ZIP files\n",
      "        🔄 Progress: 100/329\n",
      "        🔄 Progress: 200/329\n",
      "        🔄 Progress: 300/329\n",
      "      ✅ Completed EPNWA3: 329 ZIP files\n",
      "✅ Completed EPRTBJV2025000021001001: 6086 ZIPs, 12228 XML, 4621 PDF\n",
      "\n",
      "[2/5] Processing: EPRTBJV2025000024001001\n",
      "  🔄 Processing extracted directory: EPRTBJV2025000024001001\n",
      "    📂 Processing DOC folder: ../data/archive/EPO/EPRTBJV2025000024001001/DOC\n",
      "    📁 Found 11 subfolders\n",
      "      📦 EPW1B9: Processing 2 ZIP files\n",
      "      ✅ Completed EPW1B9: 2 ZIP files\n",
      "      📦 EPW1A8: Processing 2 ZIP files\n",
      "      ✅ Completed EPW1A8: 2 ZIP files\n",
      "      📦 EPW1A9: Processing 2 ZIP files\n",
      "      ✅ Completed EPW1A9: 2 ZIP files\n",
      "      📦 EPW1B8: Processing 29 ZIP files\n",
      "      ✅ Completed EPW1B8: 29 ZIP files\n",
      "      📦 EPNWB1: Processing 1673 ZIP files\n",
      "        🔄 Progress: 100/1673\n",
      "        🔄 Progress: 200/1673\n",
      "        🔄 Progress: 300/1673\n",
      "        🔄 Progress: 400/1673\n",
      "        🔄 Progress: 500/1673\n",
      "        🔄 Progress: 600/1673\n",
      "        🔄 Progress: 700/1673\n",
      "        🔄 Progress: 800/1673\n",
      "        🔄 Progress: 900/1673\n",
      "        🔄 Progress: 1000/1673\n",
      "        🔄 Progress: 1100/1673\n",
      "        🔄 Progress: 1200/1673\n",
      "        🔄 Progress: 1300/1673\n",
      "        🔄 Progress: 1400/1673\n",
      "        🔄 Progress: 1500/1673\n",
      "        🔄 Progress: 1600/1673\n",
      "      ✅ Completed EPNWB1: 1673 ZIP files\n",
      "      📦 EPNWA1: Processing 2975 ZIP files\n",
      "        🔄 Progress: 100/2975\n",
      "        🔄 Progress: 200/2975\n",
      "        🔄 Progress: 300/2975\n",
      "        🔄 Progress: 400/2975\n",
      "        🔄 Progress: 500/2975\n",
      "        🔄 Progress: 600/2975\n",
      "        🔄 Progress: 700/2975\n",
      "        🔄 Progress: 800/2975\n",
      "        🔄 Progress: 900/2975\n",
      "        🔄 Progress: 1000/2975\n",
      "        🔄 Progress: 1100/2975\n",
      "        🔄 Progress: 1200/2975\n",
      "        🔄 Progress: 1300/2975\n",
      "        🔄 Progress: 1400/2975\n",
      "        🔄 Progress: 1500/2975\n",
      "        🔄 Progress: 1600/2975\n",
      "        🔄 Progress: 1700/2975\n",
      "        🔄 Progress: 1800/2975\n",
      "        🔄 Progress: 1900/2975\n",
      "        🔄 Progress: 2000/2975\n",
      "        🔄 Progress: 2100/2975\n",
      "        🔄 Progress: 2200/2975\n",
      "        🔄 Progress: 2300/2975\n",
      "        🔄 Progress: 2400/2975\n",
      "        🔄 Progress: 2500/2975\n",
      "        🔄 Progress: 2600/2975\n",
      "        🔄 Progress: 2700/2975\n",
      "        🔄 Progress: 2800/2975\n",
      "        🔄 Progress: 2900/2975\n",
      "      ✅ Completed EPNWA1: 2975 ZIP files\n",
      "      📦 EPW2B9: Processing 1 ZIP files\n",
      "      ✅ Completed EPW2B9: 1 ZIP files\n",
      "      📦 EPW2A8: Processing 1 ZIP files\n",
      "      ✅ Completed EPW2A8: 1 ZIP files\n",
      "      📦 EPNWB2: Processing 32 ZIP files\n",
      "      ✅ Completed EPNWB2: 32 ZIP files\n",
      "      📦 EPNWA3: Processing 310 ZIP files\n",
      "        🔄 Progress: 100/310\n",
      "        🔄 Progress: 200/310\n",
      "        🔄 Progress: 300/310\n",
      "      ✅ Completed EPNWA3: 310 ZIP files\n",
      "      📦 EPNWA2: Processing 434 ZIP files\n",
      "        🔄 Progress: 100/434\n",
      "        🔄 Progress: 200/434\n",
      "        🔄 Progress: 300/434\n",
      "        🔄 Progress: 400/434\n",
      "      ✅ Completed EPNWA2: 434 ZIP files\n",
      "✅ Completed EPRTBJV2025000024001001: 5461 ZIPs, 10971 XML, 4086 PDF\n",
      "\n",
      "[3/5] Processing: EPRTBJV2025000023001001\n",
      "  🔄 Extracting main ZIP: EPRTBJV2025000023001001.zip\n",
      "    📂 Processing DOC folder: /tmp/tmpmwl7gygy/DOC\n",
      "    📁 Found 9 subfolders\n",
      "      📦 EPW1B8: Processing 20 ZIP files\n",
      "      ✅ Completed EPW1B8: 20 ZIP files\n",
      "      📦 EPW1B9: Processing 1 ZIP files\n",
      "      ✅ Completed EPW1B9: 1 ZIP files\n",
      "      📦 EPW1A9: Processing 2 ZIP files\n",
      "      ✅ Completed EPW1A9: 2 ZIP files\n",
      "      📦 EPNWA2: Processing 327 ZIP files\n",
      "        🔄 Progress: 100/327\n",
      "        🔄 Progress: 200/327\n",
      "        🔄 Progress: 300/327\n",
      "      ✅ Completed EPNWA2: 327 ZIP files\n",
      "      📦 EPNWB1: Processing 2230 ZIP files\n",
      "        🔄 Progress: 100/2230\n",
      "        🔄 Progress: 200/2230\n",
      "        🔄 Progress: 300/2230\n",
      "        🔄 Progress: 400/2230\n",
      "        🔄 Progress: 500/2230\n",
      "        🔄 Progress: 600/2230\n",
      "        🔄 Progress: 700/2230\n",
      "        🔄 Progress: 800/2230\n",
      "        🔄 Progress: 900/2230\n",
      "        🔄 Progress: 1000/2230\n",
      "        🔄 Progress: 1100/2230\n",
      "        🔄 Progress: 1200/2230\n",
      "        🔄 Progress: 1300/2230\n",
      "        🔄 Progress: 1400/2230\n",
      "        🔄 Progress: 1500/2230\n",
      "        🔄 Progress: 1600/2230\n",
      "        🔄 Progress: 1700/2230\n",
      "        🔄 Progress: 1800/2230\n",
      "        🔄 Progress: 1900/2230\n",
      "        🔄 Progress: 2000/2230\n",
      "        🔄 Progress: 2100/2230\n",
      "        🔄 Progress: 2200/2230\n",
      "      ✅ Completed EPNWB1: 2230 ZIP files\n",
      "      📦 EPNWA1: Processing 3396 ZIP files\n",
      "        🔄 Progress: 100/3396\n",
      "        🔄 Progress: 200/3396\n",
      "        🔄 Progress: 300/3396\n",
      "        🔄 Progress: 400/3396\n",
      "        🔄 Progress: 500/3396\n",
      "        🔄 Progress: 600/3396\n",
      "        🔄 Progress: 700/3396\n",
      "        🔄 Progress: 800/3396\n",
      "        🔄 Progress: 900/3396\n",
      "        🔄 Progress: 1000/3396\n",
      "        🔄 Progress: 1100/3396\n",
      "        🔄 Progress: 1200/3396\n",
      "        🔄 Progress: 1300/3396\n",
      "        🔄 Progress: 1400/3396\n",
      "        🔄 Progress: 1500/3396\n",
      "        🔄 Progress: 1600/3396\n",
      "        🔄 Progress: 1700/3396\n",
      "        🔄 Progress: 1800/3396\n",
      "        🔄 Progress: 1900/3396\n",
      "        🔄 Progress: 2000/3396\n",
      "        🔄 Progress: 2100/3396\n",
      "        🔄 Progress: 2200/3396\n",
      "        🔄 Progress: 2300/3396\n",
      "        🔄 Progress: 2400/3396\n",
      "        🔄 Progress: 2500/3396\n",
      "        🔄 Progress: 2600/3396\n",
      "        🔄 Progress: 2700/3396\n",
      "        🔄 Progress: 2800/3396\n",
      "        🔄 Progress: 2900/3396\n",
      "        🔄 Progress: 3000/3396\n",
      "        🔄 Progress: 3100/3396\n",
      "        🔄 Progress: 3200/3396\n",
      "        🔄 Progress: 3300/3396\n",
      "      ✅ Completed EPNWA1: 3396 ZIP files\n",
      "      📦 EPNWB2: Processing 30 ZIP files\n",
      "      ✅ Completed EPNWB2: 30 ZIP files\n",
      "      📦 EPW1A8: Processing 2 ZIP files\n",
      "      ✅ Completed EPW1A8: 2 ZIP files\n",
      "      📦 EPNWA3: Processing 223 ZIP files\n",
      "        🔄 Progress: 100/223\n",
      "        🔄 Progress: 200/223\n",
      "      ✅ Completed EPNWA3: 223 ZIP files\n",
      "✅ Completed EPRTBJV2025000023001001: 6231 ZIPs, 12501 XML, 4571 PDF\n",
      "\n",
      "[4/5] Processing: EPRTBJV2025000022001001\n",
      "  🔄 Extracting main ZIP: EPRTBJV2025000022001001.zip\n",
      "    📂 Processing DOC folder: /tmp/tmp_76vjouc/DOC\n",
      "    📁 Found 9 subfolders\n",
      "      📦 EPW2A8: Processing 1 ZIP files\n",
      "      ✅ Completed EPW2A8: 1 ZIP files\n",
      "      📦 EPW1B8: Processing 25 ZIP files\n",
      "      ✅ Completed EPW1B8: 25 ZIP files\n",
      "      📦 EPW1A9: Processing 3 ZIP files\n",
      "      ✅ Completed EPW1A9: 3 ZIP files\n",
      "      📦 EPNWA2: Processing 385 ZIP files\n",
      "        🔄 Progress: 100/385\n",
      "        🔄 Progress: 200/385\n",
      "        🔄 Progress: 300/385\n",
      "      ✅ Completed EPNWA2: 385 ZIP files\n",
      "      📦 EPNWB1: Processing 1350 ZIP files\n",
      "        🔄 Progress: 100/1350\n",
      "        🔄 Progress: 200/1350\n",
      "        🔄 Progress: 300/1350\n",
      "        🔄 Progress: 400/1350\n",
      "        🔄 Progress: 500/1350\n",
      "        🔄 Progress: 600/1350\n",
      "        🔄 Progress: 700/1350\n",
      "        🔄 Progress: 800/1350\n",
      "        🔄 Progress: 900/1350\n",
      "        🔄 Progress: 1000/1350\n",
      "        🔄 Progress: 1100/1350\n",
      "        🔄 Progress: 1200/1350\n",
      "        🔄 Progress: 1300/1350\n",
      "      ✅ Completed EPNWB1: 1350 ZIP files\n",
      "      📦 EPNWA1: Processing 3005 ZIP files\n",
      "        🔄 Progress: 100/3005\n",
      "        🔄 Progress: 200/3005\n",
      "        🔄 Progress: 300/3005\n",
      "        🔄 Progress: 400/3005\n",
      "        🔄 Progress: 500/3005\n",
      "        🔄 Progress: 600/3005\n",
      "        🔄 Progress: 700/3005\n",
      "        🔄 Progress: 800/3005\n",
      "        🔄 Progress: 900/3005\n",
      "        🔄 Progress: 1000/3005\n",
      "        🔄 Progress: 1100/3005\n",
      "        🔄 Progress: 1200/3005\n",
      "        🔄 Progress: 1300/3005\n",
      "        🔄 Progress: 1400/3005\n",
      "        🔄 Progress: 1500/3005\n",
      "        🔄 Progress: 1600/3005\n",
      "        🔄 Progress: 1700/3005\n",
      "        🔄 Progress: 1800/3005\n",
      "        🔄 Progress: 1900/3005\n",
      "        🔄 Progress: 2000/3005\n",
      "        🔄 Progress: 2100/3005\n",
      "        🔄 Progress: 2200/3005\n",
      "        🔄 Progress: 2300/3005\n",
      "        🔄 Progress: 2400/3005\n",
      "        🔄 Progress: 2500/3005\n",
      "        🔄 Progress: 2600/3005\n",
      "        🔄 Progress: 2700/3005\n",
      "        🔄 Progress: 2800/3005\n",
      "        🔄 Progress: 2900/3005\n",
      "        🔄 Progress: 3000/3005\n",
      "      ✅ Completed EPNWA1: 3005 ZIP files\n",
      "      📦 EPNWB2: Processing 13 ZIP files\n",
      "      ✅ Completed EPNWB2: 13 ZIP files\n",
      "      📦 EPNWB3: Processing 1 ZIP files\n",
      "      ✅ Completed EPNWB3: 1 ZIP files\n",
      "      📦 EPNWA3: Processing 173 ZIP files\n",
      "        🔄 Progress: 100/173\n",
      "      ✅ Completed EPNWA3: 173 ZIP files\n",
      "✅ Completed EPRTBJV2025000022001001: 4956 ZIPs, 9955 XML, 3602 PDF\n",
      "\n",
      "[5/5] Processing: EPRTBJV2025000024001001\n",
      "  🔄 Extracting main ZIP: EPRTBJV2025000024001001.zip\n",
      "    📂 Processing DOC folder: /tmp/tmpklxstyqm/DOC\n",
      "    📁 Found 11 subfolders\n",
      "      📦 EPW2A8: Processing 1 ZIP files\n",
      "      ✅ Completed EPW2A8: 1 ZIP files\n",
      "      📦 EPW1B8: Processing 29 ZIP files\n",
      "      ✅ Completed EPW1B8: 29 ZIP files\n",
      "      📦 EPW1B9: Processing 2 ZIP files\n",
      "      ✅ Completed EPW1B9: 2 ZIP files\n",
      "      📦 EPW1A9: Processing 2 ZIP files\n",
      "      ✅ Completed EPW1A9: 2 ZIP files\n",
      "      📦 EPNWA2: Processing 434 ZIP files\n",
      "        🔄 Progress: 100/434\n",
      "        🔄 Progress: 200/434\n",
      "        🔄 Progress: 300/434\n",
      "        🔄 Progress: 400/434\n",
      "      ✅ Completed EPNWA2: 434 ZIP files\n",
      "      📦 EPW2B9: Processing 1 ZIP files\n",
      "      ✅ Completed EPW2B9: 1 ZIP files\n",
      "      📦 EPNWB1: Processing 1673 ZIP files\n",
      "        🔄 Progress: 100/1673\n",
      "        🔄 Progress: 200/1673\n",
      "        🔄 Progress: 300/1673\n",
      "        🔄 Progress: 400/1673\n",
      "        🔄 Progress: 500/1673\n",
      "        🔄 Progress: 600/1673\n",
      "        🔄 Progress: 700/1673\n",
      "        🔄 Progress: 800/1673\n",
      "        🔄 Progress: 900/1673\n",
      "        🔄 Progress: 1000/1673\n",
      "        🔄 Progress: 1100/1673\n",
      "        🔄 Progress: 1200/1673\n",
      "        🔄 Progress: 1300/1673\n",
      "        🔄 Progress: 1400/1673\n",
      "        🔄 Progress: 1500/1673\n",
      "        🔄 Progress: 1600/1673\n",
      "      ✅ Completed EPNWB1: 1673 ZIP files\n",
      "      📦 EPNWA1: Processing 2975 ZIP files\n",
      "        🔄 Progress: 100/2975\n",
      "        🔄 Progress: 200/2975\n",
      "        🔄 Progress: 300/2975\n",
      "        🔄 Progress: 400/2975\n",
      "        🔄 Progress: 500/2975\n",
      "        🔄 Progress: 600/2975\n",
      "        🔄 Progress: 700/2975\n",
      "        🔄 Progress: 800/2975\n",
      "        🔄 Progress: 900/2975\n",
      "        🔄 Progress: 1000/2975\n",
      "        🔄 Progress: 1100/2975\n",
      "        🔄 Progress: 1200/2975\n",
      "        🔄 Progress: 1300/2975\n",
      "        🔄 Progress: 1400/2975\n",
      "        🔄 Progress: 1500/2975\n",
      "        🔄 Progress: 1600/2975\n",
      "        🔄 Progress: 1700/2975\n",
      "        🔄 Progress: 1800/2975\n",
      "        🔄 Progress: 1900/2975\n",
      "        🔄 Progress: 2000/2975\n",
      "        🔄 Progress: 2100/2975\n",
      "        🔄 Progress: 2200/2975\n",
      "        🔄 Progress: 2300/2975\n",
      "        🔄 Progress: 2400/2975\n",
      "        🔄 Progress: 2500/2975\n",
      "        🔄 Progress: 2600/2975\n",
      "        🔄 Progress: 2700/2975\n",
      "        🔄 Progress: 2800/2975\n",
      "        🔄 Progress: 2900/2975\n",
      "      ✅ Completed EPNWA1: 2975 ZIP files\n",
      "      📦 EPNWB2: Processing 32 ZIP files\n",
      "      ✅ Completed EPNWB2: 32 ZIP files\n",
      "      📦 EPW1A8: Processing 2 ZIP files\n",
      "      ✅ Completed EPW1A8: 2 ZIP files\n",
      "      📦 EPNWA3: Processing 310 ZIP files\n",
      "        🔄 Progress: 100/310\n",
      "        🔄 Progress: 200/310\n",
      "        🔄 Progress: 300/310\n",
      "      ✅ Completed EPNWA3: 310 ZIP files\n",
      "✅ Completed EPRTBJV2025000024001001: 5461 ZIPs, 10971 XML, 4086 PDF\n",
      "\n",
      "============================================================\n",
      "🎉 ALL EPO Archives Processing Completed!\n",
      "📅 End time: 14:08:14\n",
      "⏱️ Total time: 244.76 seconds (4.1 minutes)\n",
      "\n",
      "📊 Global Statistics:\n",
      "   Archives found: 5\n",
      "   Archives processed: 5\n",
      "   ZIP files processed: 28195\n",
      "   📄 XML files extracted: 56626\n",
      "   📑 PDF files extracted: 20966\n",
      "   📋 Total files extracted: 77592\n",
      "   ⏩ Files skipped: 392586\n",
      "   ❌ Errors: 0\n",
      "   📈 Processing rate: 6911.7 ZIP files/minute\n",
      "\n",
      "🎉 All done! Check your results in: ../data/raw/EPO/\n",
      "📊 Total files extracted: 77592\n"
     ]
    }
   ],
   "source": [
    "def process_all_epo_archives():\n",
    "    \"\"\"\n",
    "    Process ALL EPO archives in the archive/EPO directory\n",
    "    - Handles both ZIP files and already extracted folders\n",
    "    - Extracts only PDF and XML files\n",
    "    - Processes all archives, not just one\n",
    "    \"\"\"\n",
    "    import zipfile\n",
    "    import shutil\n",
    "    from pathlib import Path\n",
    "    import time\n",
    "    \n",
    "    # Base paths\n",
    "    epo_archive_dir = Path(\"../data/archive/EPO\")\n",
    "    epo_raw_dir = Path(\"../data/raw/EPO\")\n",
    "    \n",
    "    # Create output directory\n",
    "    epo_raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(f\"🚀 Processing ALL EPO Archives\")\n",
    "    print(f\"📂 Source directory: {epo_archive_dir}\")\n",
    "    print(f\"📁 Output directory: {epo_raw_dir}\")\n",
    "    print(f\"📅 Start time: {time.strftime('%H:%M:%S')}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not epo_archive_dir.exists():\n",
    "        print(f\"❌ EPO archive directory not found: {epo_archive_dir}\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize stats\n",
    "    global_stats = {\n",
    "        'archives_found': 0,\n",
    "        'archives_processed': 0,\n",
    "        'zip_files_processed': 0,\n",
    "        'xml_files_extracted': 0,\n",
    "        'pdf_files_extracted': 0,\n",
    "        'files_skipped': 0,\n",
    "        'errors': 0,\n",
    "        'total_zip_files': 0\n",
    "    }\n",
    "    \n",
    "    # Find all EPO archives (both ZIP files and directories)\n",
    "    archives_to_process = []\n",
    "    \n",
    "    for item in epo_archive_dir.iterdir():\n",
    "        if item.name.startswith('.'):  # Skip hidden files like .DS_Store\n",
    "            continue\n",
    "            \n",
    "        if item.is_file() and item.suffix.lower() == '.zip':\n",
    "            # Main archive ZIP file\n",
    "            archives_to_process.append({\n",
    "                'name': item.stem,\n",
    "                'path': item,\n",
    "                'type': 'main_zip'\n",
    "            })\n",
    "        elif item.is_dir() and item.name.startswith('EPRTBJV'):\n",
    "            # Already extracted archive directory\n",
    "            archives_to_process.append({\n",
    "                'name': item.name,\n",
    "                'path': item,\n",
    "                'type': 'directory'\n",
    "            })\n",
    "    \n",
    "    global_stats['archives_found'] = len(archives_to_process)\n",
    "    print(f\"🔍 Found {len(archives_to_process)} EPO archives to process:\")\n",
    "    \n",
    "    for archive in archives_to_process:\n",
    "        print(f\"  📦 {archive['name']} ({archive['type']})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    # Process each archive\n",
    "    for i, archive in enumerate(archives_to_process, 1):\n",
    "        print(f\"\\n[{i}/{len(archives_to_process)}] Processing: {archive['name']}\")\n",
    "        \n",
    "        try:\n",
    "            if archive['type'] == 'main_zip':\n",
    "                # Extract main ZIP file first\n",
    "                result = process_main_archive_zip(archive, epo_raw_dir)\n",
    "            else:\n",
    "                # Process already extracted directory\n",
    "                result = process_extracted_archive_directory(archive, epo_raw_dir)\n",
    "            \n",
    "            if result:\n",
    "                # Aggregate stats\n",
    "                for key in ['zip_files_processed', 'xml_files_extracted', 'pdf_files_extracted', 'files_skipped', 'errors']:\n",
    "                    global_stats[key] += result.get(key, 0)\n",
    "                global_stats['archives_processed'] += 1\n",
    "                \n",
    "                print(f\"✅ Completed {archive['name']}: {result.get('zip_files_processed', 0)} ZIPs, \"\n",
    "                      f\"{result.get('xml_files_extracted', 0)} XML, {result.get('pdf_files_extracted', 0)} PDF\")\n",
    "            else:\n",
    "                print(f\"❌ Failed to process {archive['name']}\")\n",
    "                global_stats['errors'] += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {archive['name']}: {e}\")\n",
    "            global_stats['errors'] += 1\n",
    "    \n",
    "    # Final results\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"🎉 ALL EPO Archives Processing Completed!\")\n",
    "    print(f\"📅 End time: {time.strftime('%H:%M:%S')}\")\n",
    "    print(f\"⏱️ Total time: {total_time:.2f} seconds ({total_time/60:.1f} minutes)\")\n",
    "    print(f\"\\n📊 Global Statistics:\")\n",
    "    print(f\"   Archives found: {global_stats['archives_found']}\")\n",
    "    print(f\"   Archives processed: {global_stats['archives_processed']}\")\n",
    "    print(f\"   ZIP files processed: {global_stats['zip_files_processed']}\")\n",
    "    print(f\"   📄 XML files extracted: {global_stats['xml_files_extracted']}\")\n",
    "    print(f\"   📑 PDF files extracted: {global_stats['pdf_files_extracted']}\")\n",
    "    print(f\"   📋 Total files extracted: {global_stats['xml_files_extracted'] + global_stats['pdf_files_extracted']}\")\n",
    "    print(f\"   ⏩ Files skipped: {global_stats['files_skipped']}\")\n",
    "    print(f\"   ❌ Errors: {global_stats['errors']}\")\n",
    "    \n",
    "    if total_time > 60:\n",
    "        print(f\"   📈 Processing rate: {global_stats['zip_files_processed']/(total_time/60):.1f} ZIP files/minute\")\n",
    "    \n",
    "    return global_stats\n",
    "\n",
    "def process_main_archive_zip(archive_info, output_base):\n",
    "    \"\"\"Process a main archive ZIP file (like EPRTBJV2025000024001001.zip)\"\"\"\n",
    "    import zipfile\n",
    "    import tempfile\n",
    "    \n",
    "    archive_zip = archive_info['path']\n",
    "    archive_name = archive_info['name']\n",
    "    \n",
    "    print(f\"  🔄 Extracting main ZIP: {archive_zip.name}\")\n",
    "    \n",
    "    try:\n",
    "        # Create temporary directory for main ZIP extraction\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            temp_path = Path(temp_dir)\n",
    "            \n",
    "            # Extract main ZIP\n",
    "            with zipfile.ZipFile(archive_zip, 'r') as zip_ref:\n",
    "                zip_ref.extractall(temp_path)\n",
    "            \n",
    "            # Look for DOC folder in extracted content\n",
    "            doc_folder = None\n",
    "            for item in temp_path.rglob('DOC'):\n",
    "                if item.is_dir():\n",
    "                    doc_folder = item\n",
    "                    break\n",
    "            \n",
    "            if not doc_folder:\n",
    "                print(f\"    ❌ No DOC folder found in {archive_zip.name}\")\n",
    "                return None\n",
    "            \n",
    "            # Process the DOC folder\n",
    "            archive_output = output_base / archive_name\n",
    "            return process_doc_folder(doc_folder, archive_output, archive_name)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ Error extracting main ZIP {archive_zip.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_extracted_archive_directory(archive_info, output_base):\n",
    "    \"\"\"Process an already extracted archive directory\"\"\"\n",
    "    archive_dir = archive_info['path']\n",
    "    archive_name = archive_info['name']\n",
    "    \n",
    "    print(f\"  🔄 Processing extracted directory: {archive_name}\")\n",
    "    \n",
    "    # Look for DOC folder\n",
    "    doc_folder = archive_dir / \"DOC\"\n",
    "    if not doc_folder.exists():\n",
    "        print(f\"    ❌ No DOC folder found in {archive_name}\")\n",
    "        return None\n",
    "    \n",
    "    # Process the DOC folder\n",
    "    archive_output = output_base / archive_name\n",
    "    return process_doc_folder(doc_folder, archive_output, archive_name)\n",
    "\n",
    "def process_doc_folder(doc_folder, output_base, archive_name):\n",
    "    \"\"\"Process the DOC folder containing ZIP files\"\"\"\n",
    "    import zipfile\n",
    "    \n",
    "    output_base.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    stats = {\n",
    "        'zip_files_processed': 0,\n",
    "        'xml_files_extracted': 0,\n",
    "        'pdf_files_extracted': 0,\n",
    "        'files_skipped': 0,\n",
    "        'errors': 0\n",
    "    }\n",
    "    \n",
    "    print(f\"    📂 Processing DOC folder: {doc_folder}\")\n",
    "    \n",
    "    # Process each subfolder in DOC\n",
    "    subfolders = [sf for sf in doc_folder.iterdir() if sf.is_dir()]\n",
    "    print(f\"    📁 Found {len(subfolders)} subfolders\")\n",
    "    \n",
    "    for subfolder in subfolders:\n",
    "        subfolder_output = output_base / subfolder.name\n",
    "        subfolder_output.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        zip_files = list(subfolder.glob(\"*.zip\"))\n",
    "        if not zip_files:\n",
    "            continue\n",
    "            \n",
    "        print(f\"      📦 {subfolder.name}: Processing {len(zip_files)} ZIP files\")\n",
    "        \n",
    "        # Process ZIP files in this subfolder\n",
    "        for j, zip_file in enumerate(zip_files, 1):\n",
    "            try:\n",
    "                # Progress update for large folders\n",
    "                if len(zip_files) > 100 and j % 100 == 0:\n",
    "                    print(f\"        🔄 Progress: {j}/{len(zip_files)}\")\n",
    "                \n",
    "                zip_output_dir = subfolder_output / zip_file.stem\n",
    "                zip_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "                    all_files = zip_ref.namelist()\n",
    "                    target_files = [f for f in all_files if f.lower().endswith(('.pdf', '.xml'))]\n",
    "                    \n",
    "                    zip_xml = 0\n",
    "                    zip_pdf = 0\n",
    "                    \n",
    "                    for file_name in target_files:\n",
    "                        try:\n",
    "                            zip_ref.extract(file_name, zip_output_dir)\n",
    "                            if file_name.lower().endswith('.xml'):\n",
    "                                zip_xml += 1\n",
    "                            elif file_name.lower().endswith('.pdf'):\n",
    "                                zip_pdf += 1\n",
    "                        except Exception:\n",
    "                            continue\n",
    "                    \n",
    "                    stats['xml_files_extracted'] += zip_xml\n",
    "                    stats['pdf_files_extracted'] += zip_pdf\n",
    "                    stats['files_skipped'] += len(all_files) - len(target_files)\n",
    "                    stats['zip_files_processed'] += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"        ❌ Error with {zip_file.name}: {e}\")\n",
    "                stats['errors'] += 1\n",
    "        \n",
    "        print(f\"      ✅ Completed {subfolder.name}: {len(zip_files)} ZIP files\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Run the comprehensive extraction\n",
    "print(\"🎯 This will process ALL EPO archives in your archive/EPO directory:\")\n",
    "print(\"  - EPRTBJV2025000021001001.zip\")\n",
    "print(\"  - EPRTBJV2025000022001001.zip\") \n",
    "print(\"  - EPRTBJV2025000023001001.zip\")\n",
    "print(\"  - EPRTBJV2025000024001001.zip\")\n",
    "print(\"  - EPRTBJV2025000024001001/ (already extracted)\")\n",
    "print(\"\\n⚠️ This may take several hours depending on the total number of ZIP files\")\n",
    "print(\"🎯 Only PDF and XML files will be kept\")\n",
    "\n",
    "proceed = input(\"\\nDo you want to process ALL EPO archives? (y/N): \")\n",
    "\n",
    "if proceed.lower() == 'y':\n",
    "    comprehensive_stats = process_all_epo_archives()\n",
    "    \n",
    "    if comprehensive_stats:\n",
    "        print(f\"\\n🎉 All done! Check your results in: ../data/raw/EPO/\")\n",
    "        print(f\"📊 Total files extracted: {comprehensive_stats['xml_files_extracted'] + comprehensive_stats['pdf_files_extracted']}\")\n",
    "else:\n",
    "    print(\"❌ Processing cancelled\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6853fba8-cc0f-429c-8ccf-5f1007d705b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
