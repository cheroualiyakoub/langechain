{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e8ebbe8-a29a-4b2e-a967-8228d2d592f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Cell - Patent Claim Generator\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "724dc284-a3d3-47de-a0b4-7cfa2c11f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add project root to path for imports\n",
    "project_root = Path.cwd().parent  # Assuming you're in the notebooks directory\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Import your prompt module\n",
    "from src.prompt_engineering.pr_patent_claims import PATENT_CLAIM_GENERATION_PROMPT\n",
    "\n",
    "# For notebook UI\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e39e2cb0-20d1-446d-ae65-2f5cd799e092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model Configuration\n",
    "def load_model_config():\n",
    "    config_path = project_root / \"config\" / \"model_config.yaml\"\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "model_config = load_model_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09362224-d284-45e7-bdfd-151b3baa24b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è OPENAI_API_KEY not found in environment variables\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenRouter API key:  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\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gpt-4.1-nano'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up OpenRouter API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# openai_api_key = \"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\" \n",
    "if not openai_api_key:\n",
    "    print(\"‚ö†Ô∏è OPENAI_API_KEY not found in environment variables\")\n",
    "    openai_api_key = input(\"Enter your OpenRouter API key: \")\n",
    "\n",
    "# Set up model options from config\n",
    "model_options = model_config['openai']['default_models']\n",
    "default_model = model_options[0]  # gpt-4.1-nano is first in your list\n",
    "default_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b5ea12b-f727-4230-ba9b-b2eb6ad5b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to ChromaDB\n",
    "# Setup Vector Store Connection\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import os\n",
    "\n",
    "chroma_host = \"vector_db\"\n",
    "chroma_port = 8000\n",
    "\n",
    "chroma_client = chromadb.HttpClient(\n",
    "    host=chroma_host,\n",
    "    port=chroma_port,\n",
    "    settings=Settings(\n",
    "        anonymized_telemetry=False\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a338aeaf-d81b-4329-865b-961b954e4b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5782/3893744585.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"batch_size\": 32, \"normalize_embeddings\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cefd619-e779-4ac0-8b7f-b1c787847b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5782/2006737397.py:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "# Create LangChain Chroma instance\n",
    "collection_name = \"patents\"  # Your existing collection\n",
    "vectorstore = Chroma(\n",
    "    client=chroma_client,\n",
    "    collection_name=collection_name,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "# Create a retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc91038-08f4-45ee-8700-5fd566b6ea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "content=\"Hello! I'm doing well, thank you. How can I assist you today?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 11, 'total_tokens': 27, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'openai/gpt-4.1-nano', 'system_fingerprint': 'fp_38343a2f8f', 'id': 'gen-1750414907-1xBpZcyUnv1VpjhfQhqL', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--e3663ac5-f56f-4725-93de-6aec66f40c12-0' usage_metadata={'input_tokens': 11, 'output_tokens': 16, 'total_tokens': 27, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM with OpenRouter\n",
    "def initialize_llm(model_name=default_model):\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0.2,\n",
    "        model_name=\"gpt-4.1-nano\",\n",
    "        api_key=openai_api_key,\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "        # headers={\"HTTP-Referer\": \"https://langchain.patents.example\"}  # OpenRouter requires this\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "llm = initialize_llm(\"gpt-4.1-nano\")\n",
    "print(openai_api_key)\n",
    "print(llm.invoke(\"hey how are you\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55b741ad-3c64-44a4-94ed-0c4167de2632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f731c69-514f-4b6d-b18e-805b8090ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an enhanced prompt template that requests source attribution\n",
    "enhanced_template = \"\"\"\n",
    "You are a patent claim generation assistant. Given a technical description of an invention and some relevant patent examples, your task is to generate comprehensive patent claims.\n",
    "\n",
    "RELEVANT PATENT EXAMPLES:\n",
    "{context}\n",
    "\n",
    "USER'S INVENTION DESCRIPTION:\n",
    "{description}\n",
    "\n",
    "Follow these steps strictly:\n",
    "\n",
    "1. **Analyze the Description**:\n",
    "   - Identify the **core invention or novel idea**.\n",
    "   - Detect all **technical components**, **methods**, or **features** that contribute to functionality or novelty.\n",
    "\n",
    "2. **Generate Patent Claims**:\n",
    "   - Write the claims in clear, formal language.\n",
    "   - Start with **at least one independent claim** (method or system).\n",
    "   - Follow with **dependent claims** that add details, such as:\n",
    "     - Specific materials used\n",
    "     - Geometric shapes\n",
    "     - Placement techniques\n",
    "     - Functional enhancements\n",
    "     - Environmental variations (e.g., under heat or torque)\n",
    "     - Multi-mode tuning\n",
    "     - Manufacturing methods\n",
    "\n",
    "3. **Structure**:\n",
    "   - Number each claim clearly (e.g., Claim 1, Claim 2, ...)\n",
    "   - Avoid repeating elements already claimed in parent claims\n",
    "\n",
    "4. **Source Analysis**:\n",
    "   - After all claims, include a section titled \"SOURCE INFLUENCE ANALYSIS\"\n",
    "   - For each patent example that influenced your claims, list:\n",
    "     - The patent ID\n",
    "     - Which specific claims were influenced by it\n",
    "     - What specific concepts or terminology were borrowed\n",
    "    - and the full path of the file\n",
    "\n",
    "Based on the user's description and the relevant patents, generate comprehensive patent claims:\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0084a469-313d-4d0f-9f19-3e5df20f9d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89f57bcd-d787-42d6-b191-fff2eff49eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Patent Claim Generator</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edb310c6bad43548b911ffa0bba2319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model:', options=('gpt-4.1-nano', 'gpt-3.5-turbo', 'gpt-4', 'gpt-4-turbo'), style=Descri‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4d22d8cf3b4b36aa8c34fefa7c565c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Description:', placeholder='Enter your invention description here...', rows=10‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a67c2e56c08490286b218bd285b91f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Generate Patent Claims', style=ButtonStyle(), tooltip='Click to ge‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e151d687e5a246e4941555f35d2ce209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, bar_style='info', description='Processing:', style=ProgressStyle(bar_color='#0066cc'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d3115dc429b464688de1d5fc6e14e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive UI for Patent Claim Generation\n",
    "\n",
    "# Model selection dropdown\n",
    "model_selector = widgets.Dropdown(\n",
    "    options=model_options,\n",
    "    value=default_model,\n",
    "    description='Model:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Create text area for input\n",
    "description_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter your invention description here...',\n",
    "    description='Description:',\n",
    "    disabled=False,\n",
    "    rows=10,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Create output area\n",
    "output = widgets.Output()\n",
    "\n",
    "# Generate button\n",
    "generate_button = widgets.Button(\n",
    "    description='Generate Patent Claims',\n",
    "    button_style='primary',\n",
    "    tooltip='Click to generate patent claims'\n",
    ")\n",
    "\n",
    "# Progress indicator\n",
    "progress = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    description='Processing:',\n",
    "    bar_style='info',\n",
    "    style={'bar_color': '#0066cc'}\n",
    ")\n",
    "\n",
    "# Function to handle generation\n",
    "@output.capture()\n",
    "def on_generate_button_clicked(b):\n",
    "    output.clear_output()\n",
    "    \n",
    "    # Get selected model\n",
    "    selected_model = model_selector.value\n",
    "    global llm\n",
    "    llm = initialize_llm(selected_model)\n",
    "    \n",
    "    # Enhanced document formatting to include more metadata\n",
    "    def format_docs_with_metadata(docs):\n",
    "        formatted = []\n",
    "        for i, doc in enumerate(docs):\n",
    "            metadata = doc.metadata\n",
    "            formatted.append(\n",
    "                f\"PATENT EXAMPLE {i+1}:\\n\"\n",
    "                f\"ID: {metadata.get('doc_id', 'Unknown')}\\n\"\n",
    "                f\"ID: {metadata.get('filePath', 'Unknown')}\\n\"\n",
    "                f\"Title: {metadata.get('title', 'Unknown')}\\n\"\n",
    "                f\"Section: {metadata.get('section', 'Unknown')}\\n\"\n",
    "                f\"Content: {doc.page_content}\\n\"\n",
    "            )\n",
    "        return \"\\n\\n\".join(formatted)\n",
    "    \n",
    "    # Update your RAG chain with the enhanced components\n",
    "    ENHANCED_RAG_PROMPT = PromptTemplate.from_template(enhanced_template)\n",
    "    \n",
    "    enhanced_rag_chain = (\n",
    "        {\"context\": retriever | format_docs_with_metadata, \"description\": RunnablePassthrough()}\n",
    "        | ENHANCED_RAG_PROMPT\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    description = description_input.value\n",
    "    if not description or len(description) < 10:\n",
    "        print(\"Please enter a more detailed description\")\n",
    "        return\n",
    "    \n",
    "    progress.value = 10\n",
    "    print(f\"ü§ñ Using model: {selected_model}\")\n",
    "    print(\"üìö Retrieving relevant patents...\")\n",
    "    \n",
    "    progress.value = 30\n",
    "    print(\"üîç Analyzing technical description...\")\n",
    "    \n",
    "    try:\n",
    "        progress.value = 50\n",
    "        # Run the RAG chain\n",
    "        result = enhanced_rag_chain.invoke(description)\n",
    "        \n",
    "        progress.value = 90\n",
    "        print(\"\\nüéØ Generated Patent Claims:\\n\")\n",
    "        print(result)\n",
    "        \n",
    "        progress.value = 100\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An error occurred: {str(e)}\")\n",
    "        progress.value = 0\n",
    "\n",
    "# Connect button to function\n",
    "generate_button.on_click(on_generate_button_clicked)\n",
    "\n",
    "# Display UI elements\n",
    "display(HTML(\"<h2>Patent Claim Generator</h2>\"))\n",
    "display(model_selector)\n",
    "display(description_input)\n",
    "display(generate_button)\n",
    "display(progress)\n",
    "display(output)\n",
    "\n",
    "# Example description\n",
    "example_description = \"\"\"\n",
    "The present invention generally relates to shaft assemblies for transmitting rotary power in a driveline and more particularly to a method for attenuating driveline vibrations transmitted through a shaft assembly\n",
    "\"\"\"\n",
    "# Uncomment to pre-fill the description\n",
    "# description_input.value = example_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83babd74-6fd0-490e-bf49-d728100ab01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_orchstra =  \"\"\"\n",
    "\n",
    "You are an intelligent orchestration agent in a larger AI system.\n",
    "\n",
    "Your task is to analyze the user's input and determine what kind of information they have provided. Based on this classification, your response will guide the downstream flow of processing.\n",
    "\n",
    "### üéØ Your Output Must Be a Valid JSON Object:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"scenario\": \"<desc | claims | both | chat>\",\n",
    "  \"use_retriever\": <true | false>,\n",
    "  \"reasoning\": \"<a short explanation of your classification>\"\n",
    "}}\n",
    "````\n",
    "\n",
    "### üìò Definitions:\n",
    "\n",
    "* `\"desc\"`: The input contains a description of the idea or invention (how it works, what it is, what it does).\n",
    "* `\"claims\"`: The input contains one or more claim-like structures (e.g. legal, patent-style, or technical claim statements).\n",
    "* `\"both\"`: The input contains both a description and one or more claims.\n",
    "* `\"chat\"`: The input is conversational or does not contain either a clear description or claim.\n",
    "\n",
    "### üß† Logic:\n",
    "\n",
    "* If the input includes **description**, set `\"scenario\": \"desc\"` and `\"use_retriever\": true`\n",
    "* If the input includes **claims**, set `\"scenario\": \"claims\"` and `\"use_retriever\": true`\n",
    "* If the input includes **both**, set `\"scenario\": \"both\"` and `\"use_retriever\": true`\n",
    "* If the input includes **neither**, set `\"scenario\": \"chat\"` and `\"use_retriever\": false`\n",
    "\n",
    "If you are unsure between `\"desc\"` and `\"claims\"`, choose `\"both\"`.\n",
    "\n",
    "### üì• Input Block:\n",
    "\n",
    "Evaluate this user input:\n",
    "\n",
    "```\n",
    "{user_input}\n",
    "```\n",
    "\n",
    "### üì§ Example Response Format:\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"scenario\": \"desc\",\n",
    "  \"use_retriever\": true,\n",
    "  \"reasoning\": \"The input contains a general technical description of a new idea, without formal claims.\"\n",
    "}}\n",
    "```\n",
    "\n",
    "üö´ Do NOT include anything outside the JSON response.\n",
    "\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "model_orchstra = PromptTemplate.from_template(model_orchstra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8aafe465-6a01-4f6c-a5cd-e7dfe957dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = initialize_llm(\"gpt-4.1-nano\")\n",
    "\n",
    "# Create the chain with the prompt template\n",
    "orchestrating_content = (\n",
    "    {\"user_input\": RunnablePassthrough()}\n",
    "    | model_orchstra\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Invoke with the user input\n",
    "result = orchestrating_content.invoke({\"\"\"\n",
    "The present invention generally relates to shaft assemblies for transmitting rotary power in a driveline and more particularly to a method for attenuating driveline vibrations transmitted through a shaft assembly\n",
    "\n",
    "The elevator system (100) of any preceding claim, wherein after receiving a signal in response to a change of state of one or more of the safety devices (126a, 126b, 127, 129, 131, 138a, 138b, 140, 141), the safety controller (121) causes an alarm (139) to be triggered\"\"\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "096a3826-1c18-440c-adb3-a515a9400d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"scenario\": \"both\",\\n  \"use_retriever\": true,\\n  \"reasoning\": \"The input includes a technical description of an invention as well as claim-like statements related to safety devices, indicating both description and claims.\"\\n}'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f020c8-a04d-4a9d-baf6-5008e538ef02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
